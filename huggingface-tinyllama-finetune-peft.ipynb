{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Upvote if this starter Notebook helps","metadata":{}},{"cell_type":"markdown","source":"### User Input: Give me a sky blue color.\n### LLM response: #6092ff","metadata":{}},{"cell_type":"markdown","source":"# Import Required Library","metadata":{}},{"cell_type":"code","source":"!pip install -q bitsandbytes accelerate loralib trl \n!pip install -q git+https://github.com/huggingface/peft.git\n!pip install -U git+https://github.com/huggingface/transformers.git\n!pip install -U git+https://github.com/huggingface/accelerate.git\n!pip install -U datasets","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset, Dataset\nfrom peft import LoraConfig,AutoPeftModelForCausalLM,PeftModel\nfrom transformers import AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig,TrainingArguments,pipeline\nfrom trl import SFTTrainer\nfrom time import perf_counter\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:23:53.266118Z","iopub.execute_input":"2024-01-24T08:23:53.266494Z","iopub.status.idle":"2024-01-24T08:24:00.872662Z","shell.execute_reply.started":"2024-01-24T08:23:53.266462Z","shell.execute_reply":"2024-01-24T08:24:00.871673Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Define params","metadata":{}},{"cell_type":"code","source":"class CFG:\n    dataset_id=\"burkelibbey/colors\"\n    base_model_id=\"PY007/TinyLlama-1.1B-Chat-v0.3\"\n    output_directory=\"tinyllama-colorist-lora\"\n    access_token=\"Paste your key\"\n\ncfg = CFG()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:02.901119Z","iopub.execute_input":"2024-01-24T08:24:02.901510Z","iopub.status.idle":"2024-01-24T08:24:02.908137Z","shell.execute_reply.started":"2024-01-24T08:24:02.901478Z","shell.execute_reply":"2024-01-24T08:24:02.906791Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Prepare the dataset using template f\"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant\\n{answer}<|im_end|>\\n\"\n\n---\n\n","metadata":{}},{"cell_type":"code","source":"def format_data(dataset_id):\n    data = load_dataset(dataset_id,split=\"train\")\n    data_df = data.to_pandas()\n    data_df[\"text\"] = data_df[[\"description\", \"color\"]].apply(lambda x: \"<|im_start|>user\\n\" + x[\"description\"] + \" <|im_end|>\\n<|im_start|>assistant\\n\" + x[\"color\"] + \"<|im_end|>\\n\", axis=1)\n    data = Dataset.from_pandas(data_df)\n    data = data.train_test_split(seed=42, test_size=0.2)\n    return data","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:05.486736Z","iopub.execute_input":"2024-01-24T08:24:05.487233Z","iopub.status.idle":"2024-01-24T08:24:05.493729Z","shell.execute_reply.started":"2024-01-24T08:24:05.487205Z","shell.execute_reply":"2024-01-24T08:24:05.492535Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data = format_data(cfg.dataset_id)\ndata","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:11.050883Z","iopub.execute_input":"2024-01-24T08:24:11.051859Z","iopub.status.idle":"2024-01-24T08:24:14.776303Z","shell.execute_reply.started":"2024-01-24T08:24:11.051823Z","shell.execute_reply":"2024-01-24T08:24:14.775348Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21132765af4647b1831ebbf3af74dad9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.38M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6edb523dc9a45cd97d8f442bf902443"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55f7fd979dc4d53857c4acf11147809"}},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['color', 'description', 'text'],\n        num_rows: 27109\n    })\n    test: Dataset({\n        features: ['color', 'description', 'text'],\n        num_rows: 6778\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"data['train'][0]","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:14.778095Z","iopub.execute_input":"2024-01-24T08:24:14.778463Z","iopub.status.idle":"2024-01-24T08:24:14.785853Z","shell.execute_reply.started":"2024-01-24T08:24:14.778428Z","shell.execute_reply":"2024-01-24T08:24:14.784966Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"{'color': '#20a080',\n 'description': \"Medium blue-green: This shade is a medium intensity blue-green, somewhat similar to the color of a tropical ocean. It's a cool color that straddles the line between blue and green, but is slightly more on the green side.\",\n 'text': \"<|im_start|>user\\nMedium blue-green: This shade is a medium intensity blue-green, somewhat similar to the color of a tropical ocean. It's a cool color that straddles the line between blue and green, but is slightly more on the green side. <|im_end|>\\n<|im_start|>assistant\\n#20a080<|im_end|>\\n\"}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Define tokenizer model","metadata":{}},{"cell_type":"code","source":"def get_tokenizer_and_model(model_id):\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    tokenizer.pad_token = tokenizer.eos_token\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=\"float16\", bnb_4bit_use_double_quant=True\n    )\n    model = AutoModelForCausalLM.from_pretrained(model_id,quantization_config=bnb_config, device_map=\"auto\")\n    model.config.use_cache=False\n    model.config.pretraining_tp=1\n    return model,tokenizer\n\nmodel,tokenizer = get_tokenizer_and_model(cfg.base_model_id)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:20.589837Z","iopub.execute_input":"2024-01-24T08:24:20.590760Z","iopub.status.idle":"2024-01-24T08:24:41.837953Z","shell.execute_reply.started":"2024-01-24T08:24:20.590718Z","shell.execute_reply":"2024-01-24T08:24:41.837105Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cd9cc7dbe204a4b8fd5d24bf6b33619"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0d40a4b135984ce3b2ef0be62dfed169"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7f9fd49a3b04c9a944ac3043bbc94b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcd5c82b9f3c49618b0b10c46d7a194a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/96.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bf9de7bdf6241718959e32edde01f39"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8241e2d708534334af04cbe8319ecc18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/4.40G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce4f90ebdd7a4d279727485ee5d3b7ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cf31f297e4e4365ae9407afe7aaf333"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Finetune TinyLLama","metadata":{}},{"cell_type":"code","source":"peft_config = LoraConfig(\n    r=8,lora_alpha=16,lora_dropout=0.05,bias=\"none\",task_type=\"CAUSAL_LM\"\n)\ntraining_arguments = TrainingArguments(\n    output_dir=cfg.output_directory,\n    per_device_train_batch_size=8,\n    gradient_accumulation_steps=4,\n    optim=\"paged_adamw_32bit\",\n    learning_rate=2e-4,\n    lr_scheduler_type=\"cosine\",\n    save_strategy=\"epoch\",\n    logging_steps=10,\n    num_train_epochs=1,\n    max_steps=200,\n    fp16=True,\n    push_to_hub=False\n)\ntrainer = SFTTrainer(\n        model=model,\n        train_dataset=data['train'],\n        eval_dataset=data['test'],\n        peft_config=peft_config,\n        dataset_text_field=\"text\",\n        args=training_arguments,\n        tokenizer=tokenizer,\n        packing=False,\n        max_seq_length=1024\n    )","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:41.839759Z","iopub.execute_input":"2024-01-24T08:24:41.840446Z","iopub.status.idle":"2024-01-24T08:24:45.393897Z","shell.execute_reply.started":"2024-01-24T08:24:41.840406Z","shell.execute_reply":"2024-01-24T08:24:45.392958Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27109 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03ce34d1e5e1412c9b20df703d25e37c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6778 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d809acede5948c9a6c5a80401017b86"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:24:45.395384Z","iopub.execute_input":"2024-01-24T08:24:45.395680Z","iopub.status.idle":"2024-01-24T08:32:43.236026Z","shell.execute_reply.started":"2024-01-24T08:24:45.395654Z","shell.execute_reply":"2024-01-24T08:32:43.235035Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  \n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.16.2"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240124_082505-4mw1t1qb</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ssarkar4445/huggingface/runs/4mw1t1qb' target=\"_blank\">radiant-hill-4</a></strong> to <a href='https://wandb.ai/ssarkar4445/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ssarkar4445/huggingface' target=\"_blank\">https://wandb.ai/ssarkar4445/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ssarkar4445/huggingface/runs/4mw1t1qb' target=\"_blank\">https://wandb.ai/ssarkar4445/huggingface/runs/4mw1t1qb</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [200/200 07:04, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>2.698400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.378900</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.047000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.797700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.668500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.595400</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.508700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.489200</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.442300</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.444400</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.400100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>1.393200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.365200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.352600</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.364200</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.369000</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.362500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.356400</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.356200</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.365700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=200, training_loss=1.5877786588668823, metrics={'train_runtime': 476.7214, 'train_samples_per_second': 13.425, 'train_steps_per_second': 0.42, 'total_flos': 3073578732158976.0, 'train_loss': 1.5877786588668823, 'epoch': 0.24})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Evaluate","metadata":{}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:32:43.237913Z","iopub.execute_input":"2024-01-24T08:32:43.238326Z","iopub.status.idle":"2024-01-24T08:36:30.452521Z","shell.execute_reply.started":"2024-01-24T08:32:43.238289Z","shell.execute_reply":"2024-01-24T08:36:30.450524Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='848' max='848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [848/848 03:47]\n    </div>\n    "},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.3607922792434692,\n 'eval_runtime': 227.1998,\n 'eval_samples_per_second': 29.833,\n 'eval_steps_per_second': 3.732,\n 'epoch': 0.24}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Merging base model and peft trained model","metadata":{}},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(cfg.base_model_id,torch_dtype=torch.float16, load_in_8bit=False,\n                                             device_map=\"auto\",\n                                             trust_remote_code=True)\npeft_model = PeftModel.from_pretrained(model,'/kaggle/working/tinyllama-colorist-lora/checkpoint-200',from_transformers=True, device_map={\"\":0})\nmodel = peft_model.merge_and_unload()","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:39:03.104097Z","iopub.execute_input":"2024-01-24T08:39:03.104893Z","iopub.status.idle":"2024-01-24T08:39:05.846090Z","shell.execute_reply.started":"2024-01-24T08:39:03.104855Z","shell.execute_reply":"2024-01-24T08:39:05.844946Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model_id_colorist_final=\"ssarkar4445/tinyllama-colorist-peft\"\nmodel.push_to_hub(model_id_colorist_final,token=cfg.access_token)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:39:05.933486Z","iopub.execute_input":"2024-01-24T08:39:05.933876Z","iopub.status.idle":"2024-01-24T08:39:05.940332Z","shell.execute_reply.started":"2024-01-24T08:39:05.933843Z","shell.execute_reply":"2024-01-24T08:39:05.938975Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(cfg.base_model_id)\ntokenizer.push_to_hub(model_id_colorist_final,token=cfg.access_token)","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:39:07.386802Z","iopub.execute_input":"2024-01-24T08:39:07.387660Z","iopub.status.idle":"2024-01-24T08:39:09.119050Z","shell.execute_reply.started":"2024-01-24T08:39:07.387623Z","shell.execute_reply":"2024-01-24T08:39:09.117985Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"605c2a0684da43a099502ee6a33505c1"}},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/ssarkar4445/tinyllama-colorist-peft/commit/58b88a94bb25d486143811cfa4c685b5b51eb3fc', commit_message='Upload tokenizer', commit_description='', oid='58b88a94bb25d486143811cfa4c685b5b51eb3fc', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Model Inference","metadata":{}},{"cell_type":"code","source":"model_id_colorist_final=\"ssarkar4445/tinyllama-colorist-peft\"\n\n\ndef formatted_prompt(question)-> str:\n    return f\"<|im_start|>user\\n{question}<|im_end|>\\n<|im_start|>assistant:\"\n\n\ntokenizer = AutoTokenizer.from_pretrained(model_id_colorist_final)\npipe = pipeline(\n    \"text-generation\",\n    model=model_id_colorist_final,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n)\n\nstart_time = perf_counter()\n\nprompt = formatted_prompt('give me a pure brown color')\n\nsequences = pipe(\n    prompt,\n    do_sample=True,\n    temperature=0.1,\n    top_p=0.9,\n    num_return_sequences=1,\n    eos_token_id=tokenizer.eos_token_id,\n    max_new_tokens=12\n)\nfor seq in sequences:\n    print(f\"Result: {seq['generated_text']}\")\n\noutput_time = perf_counter() - start_time\nprint(f\"Time taken for inference: {round(output_time,2)} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-01-24T08:39:13.790493Z","iopub.execute_input":"2024-01-24T08:39:13.791207Z","iopub.status.idle":"2024-01-24T08:39:26.902853Z","shell.execute_reply.started":"2024-01-24T08:39:13.791169Z","shell.execute_reply":"2024-01-24T08:39:26.901603Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fee6fced0a345c1a3d20644c9bc88a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"853b4ff4257d4d1b9626ca72ef83e607"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f542371b915840ffb03897181b045be2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/69.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aab496e547e242668cf4b802b4c28c42"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/550 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bad545894585460181f7f7c2167775f1"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"347ce30d665f4da6bc8d14e143532298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b20de4905fe4a248cd1a49a6574f5df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/68.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccb07d677d5a4c48a59bc9fb35e43b17"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Result: <|im_start|>user\ngive me a pure brown color<|im_end|>\n<|im_start|>assistant: #806055 \n\nTime taken for inference: 1.91 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}